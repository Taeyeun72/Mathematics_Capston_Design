{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f54ac6",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46cc031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamo import hangul_to_jamo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob, librosa, re, scipy\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "# Hyperparameters for Generating Mel-spectrogram \n",
    "sample_rate = 22050\n",
    "preemphasis = 0.97\n",
    "n_fft = 1024\n",
    "hop_length = 256\n",
    "win_length = 1024\n",
    "ref_db = 20\n",
    "max_db = 100\n",
    "mel_dim = 80\n",
    "\n",
    "# Major Hyperparameters\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1a8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamo import hangul_to_jamo\n",
    "\n",
    "PAD = '_'\n",
    "EOS = '~'\n",
    "SPACE = ' '\n",
    "\n",
    "JAMO_LEADS = \"\".join([chr(_) for _ in range(0x1100, 0x1113)])\n",
    "JAMO_VOWELS = \"\".join([chr(_) for _ in range(0x1161, 0x1176)])\n",
    "JAMO_TAILS = \"\".join([chr(_) for _ in range(0x11A8, 0x11C3)])\n",
    "ETC = \".!?\"\n",
    "\n",
    "VALID_CHARS = JAMO_LEADS + JAMO_VOWELS + JAMO_TAILS + SPACE + ETC\n",
    "symbols = PAD + EOS + VALID_CHARS\n",
    "\n",
    "_symbol_to_id = {s: i for i, s in enumerate(symbols)}\n",
    "_id_to_symbol = {i: s for i, s in enumerate(symbols)}\n",
    "\n",
    "# text를 초성, 중성, 종성으로 분리하여 id로 반환하는 함수\n",
    "def text_to_sequence(text):\n",
    "    sequence = []\n",
    "    if not 0x1100 <= ord(text[0]) <= 0x1113:\n",
    "        text = ''.join(list(hangul_to_jamo(text)))\n",
    "    for s in text:\n",
    "        sequence.append(_symbol_to_id[s])\n",
    "    sequence.append(_symbol_to_id['~'])\n",
    "    return sequence\n",
    "\n",
    "def sequence_to_text(sequence):\n",
    "    result = ''\n",
    "    for symbol_id in sequence:\n",
    "        if symbol_id in _id_to_symbol:\n",
    "            s = _id_to_symbol[symbol_id]\n",
    "            result += s\n",
    "    return result.replace('}{', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce57d553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 3076/3076 [00:01<00:00, 1645.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"C:/Users/Poco/Jupyter/PaperReview/dataset/filelists-20200801.zip\"\n",
    "text_dir = data_dir + \"/ljs_audio_text_train_filelist.txt\"\n",
    "filters = '([,])'\n",
    "\n",
    "metadata = pd.read_csv(text_dir, dtype='object', sep='|', header=None)\n",
    "text = metadata[1].values\n",
    "\n",
    "out_dir = data_dir + '/data'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs(out_dir + '/text', exist_ok=True)\n",
    "os.makedirs(out_dir + '/wav', exist_ok=True)\n",
    "os.makedirs(out_dir + '/mel', exist_ok=True)\n",
    "\n",
    "# text\n",
    "print('Load Text')\n",
    "text_len = []\n",
    "for idx, s in enumerate(tqdm(text)):\n",
    "    # 문자열에서 정규표현식을 이용하여 특정 문자열을 필터링하고,\n",
    "    # 이를 빈 문자열('')로 대체한다.\n",
    "    sentence = re.sub(re.compile(filters), '', s)\n",
    "    sentence = text_to_sequence(sentence)\n",
    "    \n",
    "    text_len.append(len(sentence))\n",
    "    text_name = 'sce-text-%05d.npy' % idx\n",
    "    np.save(os.path.join(out_dir + '/text', text_name), sentence, allow_pickle=False)\n",
    "print('Text Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c41de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFi-GAN 저자 구현\n",
    "def mel_spectrogram(y, n_fft=1024, num_mels=80, sampling_rate=22050, hop_size=256, win_size=1024, fmin=0, fmax=8000, center=False):\n",
    "    \"\"\"\n",
    "    if torch.min(y) < -1.:\n",
    "        print('min value is ', torch.min(y))\n",
    "    if torch.max(y) > 1.:\n",
    "        print('max value is ', torch.max(y))\n",
    "    \"\"\"\n",
    "\n",
    "    mel = librosa.filters.mel(sampling_rate, n_fft, num_mels, fmin, fmax)\n",
    "    \n",
    "    y = torch.nn.functional.pad(y.unsqueeze(1), (int((n_fft-hop_size)/2), int((n_fft-hop_size)/2)), mode='reflect')\n",
    "    y = y.squeeze(1)\n",
    "\n",
    "    spec = torch.stft(y, n_fft, hop_length=hop_size, win_length=win_size, window=torch.hann_window(win_size).to(y.device),\n",
    "                      center=center, pad_mode='reflect', normalized=False, onesided=True)\n",
    "\n",
    "    spec = torch.sqrt(spec.pow(2).sum(-1)+(1e-9))\n",
    "\n",
    "    spec = torch.matmul(torch.from_numpy(mel).float().to(y.device), spec)\n",
    "    spec = torch.log(torch.clamp(spec, min=1e-5) * 1)\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2292785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/3076 [00:00<?, ?it/s]C:\\Users\\Poco\\anaconda3\\lib\\site-packages\\torch\\functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\SpectralOps.cpp:804.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "100%|███████████████████████████████████████████████████████████| 3076/3076 [00:20<00:00, 148.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# audio\n",
    "wav_dir = metadata[0].values\n",
    "\n",
    "print('Load Audio')\n",
    "for idx, fn in enumerate(tqdm(wav_dir)):\n",
    "    file_dir = data_dir + \"/\" +fn\n",
    "    wav, _ = librosa.load(file_dir, sr=sample_rate)\n",
    "    wav, _ = librosa.effects.trim(wav) # 묵음 제거\n",
    "    \n",
    "    mel = mel_spectrogram(torch.tensor(wav).unsqueeze(0)) # (1, 80, F)\n",
    "    mel = mel.squeeze(0).T # (F, 80)\n",
    "    mel = mel.numpy()\n",
    "\n",
    "    mel_name = 'sce-mel-%05d.npy' % idx\n",
    "    np.save(os.path.join(out_dir + '/mel', mel_name), mel, allow_pickle=False)\n",
    "    \n",
    "    # Wavenet vocoder에서 이용할 wav 파일을 추가로 저장함.\n",
    "    wav_name = 'sce-wav-%05d.npy' % idx\n",
    "    np.save(os.path.join(out_dir + '/wav', wav_name), wav, allow_pickle=False)\n",
    "\n",
    "print('Audio Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80456aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
